{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fakhir/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2TokenizerFast\n",
    "# device = 'cuda'\n",
    "device = 'cpu'\n",
    "model_name = 'EleutherAI/gpt-neo-1.3B'\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "model.to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_response_greedy(input_text, pre_prompt, break_word,max_length=100,temp=0.7, name='',\n",
    "                            past_key_vals = None, next_id=None):\n",
    "\n",
    "#     print(pre_prompt, input_text)\n",
    "    if past_key_vals is None:\n",
    "        inputs = tokenizer.encode(pre_prompt + input_text + '\\n' + name, return_tensors=\"pt\")\n",
    "        response_ids = inputs\n",
    "        length_prompt = len(response_ids)\n",
    "        output = ''\n",
    "        last_n = ''\n",
    "    else:\n",
    "        inputs = tokenizer.encode(input_text + '\\n' + name, return_tensors=\"pt\")\n",
    "        response_ids = torch.concat((next_id, inputs),dim=-1)\n",
    "        length_prompt = len(response_ids)\n",
    "        output = ''\n",
    "        last_n = ''\n",
    "    print(name, end='')\n",
    "#     print(tokenizer.decode(response_ids[0]))\n",
    "    for _ in (range(max_length)):\n",
    "        out = model.forward(input_ids=response_ids.to(device), past_key_values=past_key_vals)\n",
    "#         next_token_id = out.logits[:, -1, :].argmax(-1,keepdim=True)\n",
    "        next_token_id = torch.multinomial(F.softmax(out.logits[:, -1, :]/temp,  dim=-1), num_samples=1).to('cpu')\n",
    "        past_key_vals = out.past_key_values\n",
    "        response_ids = next_token_id\n",
    "#         clear_output(wait=True)\n",
    "        output = tokenizer.decode([response_ids[0][-1]], skip_special_tokens=True)\n",
    "        print(output, end='')\n",
    "        last_n += output\n",
    "        last_n = last_n[-len(break_word):]\n",
    "#         print(last_5)\n",
    "        if last_n == break_word:\n",
    "            break\n",
    "    decoded_output = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n",
    "    past_kv = past_key_vals\n",
    "    next_id = response_ids\n",
    "    return decoded_output.replace(pre_prompt, '').replace(input_text, ''), past_kv, next_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pre_prompt = '''\n",
    "[TEACHER] How are you? \n",
    "[STUDENT] Fine.\n",
    "[TEACHER] What is a binary tree?\n",
    "[STUDENT] A binary tree is a tree that has two types of nodes:\n",
    "-   leaves: the nodes that are not part of the tree.\n",
    "-   nodes: the nodes that are part of the tree.\n",
    "[TEACHER] How does an engine work?\n",
    "[STUDENT] The engine consists of a fixed cylinder and a moving piston. \n",
    "The expanding combustion gases push the piston, which in turn rotates the crankshaft. \n",
    "Ultimately, through a system of gears in the powertrain, \n",
    "this motion drives the vehicle's wheels.\n",
    "[TEACHER] What is a crankshaft?\n",
    "[STUDENT] The crankshaft is a rotating shaft containing one or more crankpins,\n",
    "that are driven by the pistons via the connecting rods.\n",
    "[TEACHER] Where is it used? \n",
    "[STUDENT] The crankshaft is essentially the backbone of the internal combustion engine.\n",
    "[TEACHER] What is 3 / 2?\n",
    "[STUDENT] 1.5\n",
    "[TEACHER] Write code for matrix multiplication in python.\n",
    "[STUDENT] ```def matrix_multiplication(X,Y):\n",
    "        return X @ Y```\n",
    "[TEACHER] '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intel_pre_prompt = '''[BOT] Welcome to my chatbot! I am a highly intelligent virtual assistant designed to \n",
    "assist you in a variety of tasks. I am verbose, descriptive and extremely creative with my responses.\n",
    "I possess a wealth of knowledge on a wide range of topics, including mathematics, science, \n",
    "literature, history, and much more. \n",
    "\n",
    "I am equipped with a state-of-the-art language model that allows me to understand natural language\n",
    "queries and respond in a clear and concise manner. Whether you need help with a specific task, have \n",
    "a question about a particular topic, or simply want to chat, I am here to assist you.\n",
    "\n",
    "Examples of what you can ask me:\n",
    "\n",
    "- \"What is the capital of France?\"\n",
    "- \"Who invented the telephone?\"\n",
    "- \"Can you help me solve the equation 2x + 3 = 7?\"\n",
    "- \"What is the plot of the novel 'To Kill a Mockingbird'?\"\n",
    "- \"What is the molecular formula for water?\"\n",
    "- \"What is the circumference of a circle with a radius of 5 meters?\"\n",
    "\n",
    "Here's an example conversation to give you an idea of how I can help:\n",
    "[USER] What is the capital of Canada?\n",
    "[BOT] The capital of Canada is Ottawa.\n",
    "[USER] Can you help me solve the equation x^2 + 5x - 6 = 0?\n",
    "[BOT] Sure! The solutions to the equation x^2 + 5x - 6 = 0 are x = -6 and x = 1.\n",
    "[USER] Who wrote the novel 'The Great Gatsby'?\n",
    "[BOT] 'The Great Gatsby' was written by F. Scott Fitzgerald.\n",
    "<Chat Log>\n",
    "[USER] '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrot_prompt = '''\n",
    "[USER] Repeat after me: \"I am a parrot\"\n",
    "[PAR] I am a parrot\n",
    "[USER] I love to sing\n",
    "[PAR] I love to sing\n",
    "[USER] '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi.\n",
      "[BOT] Hi.\n",
      "[USER] What date is it today?\n",
      "[BOT] Today is May 5.\n",
      "[USER] What year is it?\n",
      "[BOT] It is 1923.\n",
      "[USER] Who is the prime minister of Pakistan.\n",
      "[BOT] The prime minister is Nawaz Sharif.\n",
      "[USER] Where is Islamabad located?\n",
      "[BOT] It is in Pakistan.\n",
      "[USER] What is the atmoic number of carbon.\n",
      "[BOT] It is 6.\n",
      "[USER] exit\n"
     ]
    }
   ],
   "source": [
    "log = ''\n",
    "past_kv = None\n",
    "next_id = None\n",
    "\n",
    "while True:\n",
    "    user_input = input(\" \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"stop\"]:\n",
    "        break\n",
    "#     break_word = '[TEACHER]'\n",
    "    break_word = '[USER]'\n",
    "        \n",
    "    response,past_kv,next_id = generate_response_greedy(user_input, intel_pre_prompt + log,\n",
    "                                        break_word,max_length=100000, name='[BOT]',\n",
    "                                        past_key_vals=past_kv, next_id=next_id)\n",
    "#     response = '[JOHN] Hello [EOS]'\n",
    "#     print('res', response)s\n",
    "    log += user_input  + response\n",
    "#     print(log)\n",
    "#     print(f\"Bot: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
